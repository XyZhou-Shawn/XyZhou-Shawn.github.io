<!doctype html>
<html>

<head>
  <title>Xiaoyu Zhou</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <!-------------------------------------------------------------------------------------------->
        <!--Start Intro-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <!-- <img class="image" src="img/dummay-img.png"> -->
            <img class="image max-width-200" src="img/Xiaoyu_Zhou.jpg">
          </div>
          <div class="flex-item flex-column">
            <h2>Xiaoyu Zhou</h2>
            <hr>
            <p class="text text-large">
              <!-- yimingxie@zju.edu.cn<br> -->
              xiaoyu_zhou@stu.pku.edu.cn<br>
              xyrain.zhou@gmail.com<br>
              Ph.D. student, 
              <a target="_blank" href="https://www.northeastern.edu/">@Peking University</a><br>
              Beijing, China<br>
              <!--<a href="./others/cv.pdf">CV</a> âˆ™ -->
              <a href="xyrain.zhou@gmail.com">E-mail</a><br>
              <a href="https://scholar.google.com/citations?user=WLE4TUoAAAAJ&hl=zh-CN">Google Scholar</a><br>
              <a href="https://github.com/VDIGPKU">GitHub</a><br>
              <a href="www.linkedin.com/in/xyrain-zhou">Linkedin</a><br>
              <!-- -Applying for MS/PhD!- -->
            </p>
          </div>
          <div class="flex-item flex-item-stretch flex-column">
            <h3>Latest News</h3>
            <ul>
              <li>[Aug 22, 2025] one paper accepted to Neurips'25</li>
              <li>[Mar 15, 2024] one paper accepted to ICCV'25</li>
              <li>[Jul 13, 2023] one paper accepted to ICML'24</li>
              <li>[Mar 2, 2022] one paper accepted to CVPR'24</li>
              <!-- <li>[Jul 22, 2021] one paper accepted to ICCV'21</li> -->
              <!-- <li>[Apr 29, 2021] one paper accepted to TPAMI'21</li> -->
              <!-- <li>[Feb 29, 2021] one paper accepted to CVPR'21 (oral)</li> -->
              <!-- <li>[Feb 24, 2020] one paper accepted to CVPR'20</li> -->
              <!-- <li>[Nov 6, 2018] I will join SenseTime as a research intern. </li> -->
            </ul>
          </div>
        </div>
        <!--End Intro-->
        <!-------------------------------------------------------------------------------------------->
        <!--About Me-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">About Me</h2>
            <hr>
            <p class="text text-large">
              I am currently a 3rd year Ph.D. candidate at <a href="https://www.icst.pku.edu.cn/index.htm">Wangxuan Institute of Computer Technology, Peking University</a> supervised by <a href="https://jianghz.me/">Prof. Yongtao Wang</a>.
              My research interests center on 3D vision, spatial intelligence, and world modeling, with a focus on building a universal, real-world oriented generative 3D simulator grounded in physical principles.
              <!-- I previously worked as a research assistant in <a target="_blank" href="http://www.cad.zju.edu.cn/english.html"> State Key Lab of CAD & CG, Zhejiang University</a>  -->
              <!-- supervised by <a href="http://www.cad.zju.edu.cn/home/xzhou/">Prof. Xiaowei Zhou</a>. -->
              <!-- Before that, I was a research intern at 3D&AR Group of <a target="_blank" href="https://www.sensetime.com/">SenseTime</a> supervised by <a href="https://jiamingsun.ml/">Jiaming Sun</a>. -->
              <!-- I received my Bachelor's degree in 2019 from <a href="http://www.zju.edu.cn/english/"> Zhejiang University(ZJU)</a>, advised by <a href="http://www.cad.zju.edu.cn/home/xzhou/">Prof. Xiaowei Zhou</a>. -->
              <!-- I am a recipient of the <a href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2024">2024 Apple Scholars in AI/ML PhD fellowship</a>. -->
              <!-- My interest lies in 3D computer vision and machine learning with a focus on 3D understanding and reconstruction with a hybrid of geometric and learning-based approaches. <br> -->
              <!-- My research interest lies in computer vision and generative AI. -->
              <br><br>
              <font color="red">I am seeking a visiting PhD student position for fall 2026.</font>
            </p>
          </div>
        </div>
        <!--End About Me-->
        <!-------------------------------------------------------------------------------------------->
        <!-- Research Interests -->
        <!-- <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Research Interests</h2>
            <hr>
            <p class="text">
              My interest lies in 3D computer vision and machine learning with a focus on 3D understanding and reconstruction with a hybrid of geometric and learning-based approaches. 
            </p>
          </div>
        </div> -->
        <!--End Research Interests-->
        <!-------------------------------------------------------------------------------------------->
        <!--Preprints-->
        <!-- <div class="flex-row"> -->
          <!-- <div class="flex-item flex-column"> -->
            <!-- <h2 class="add-top-margin">Preprints</h2> -->
            <!-- <hr> -->
          <!-- </div> -->
        <!-- </div> -->
        <!-- <div class="flex-row"> -->
          <!-- <div class="flex-item flex-item-stretch flex-column"> -->
            <!-- <iframe width="240" height="135" src="https://www.youtube.com/embed/KrbomIPfhko" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br> -->
          <!-- </div> -->
          <!-- <div class="flex-item flex-item-stretch-4 flex-column"> -->
            <!-- <p class="text">
              <b>You Don't Only Look Once: Constructing Spatial-Temporal Memory for Integrated 3D Object Detection and Tracking</b><br>
              <b>Xiaoyu Zhou*</b>, Jiaming Sun*, Siyu Zhang, Linghao Chen, Guofeng Zhang, Hujun Bao, Xiaowei Zhou. (*-indicates equal contributions)<br> -->
              <!-- <a href="./contribution/udolo_contribution.html">My contribution</a> -->
            <!-- </p> -->
          <!-- </div> -->
        <!-- </div> -->
        <!--End Preprints-->
        <!-------------------------------------------------------------------------------------------->
        <!--Publications-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Research</h2>
            <hr>
            <div class="category-filters">
              <button class="category-btn active" data-category="selected">Selected</button>
              <button class="category-btn" data-category="3d-reconstruction">3D Reconstruction</button>
              <button class="category-btn" data-category="3d-generation">3D Generation</button>
              <button class="category-btn" data-category="3d-understanding">3D Understanding</button>
              <button class="category-btn" data-category="all">All</button>
            </div>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="3d-reconstruction selected all">
          <div class="flex-item flex-item-stretch flex-column">
            <video width="240" height="175" src="img/sampling.mp4" title="SAMPLING video loading.." playsinline="" autoplay="" loop="" preload="" muted=""></video>
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>	SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image</b><br>
              <b>Xiaoyu Zhou</b>, Zhiwei Lin, Xiaojun Shan, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang.
              (* equal contribution) <br>
              <i>International Conference on Computer Vision (ICCV), 2023.</i> <br>
              [<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.html">PDF</a>]
            </p>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="3d-reconstruction selected all">
          <div class="flex-item flex-item-stretch flex-column">
            <img width="240" height="125" src="img/dg.png" alt="method preview">
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>Drivinggaussian: Composite gaussian splatting for surrounding dynamic autonomous driving scenes</b><br>
              <b>Xiaoyu Zhou</b>, Zhiwei Lin, Xiaojun Shan, Yongtao Wang, Deqing Sun^, Ming-Hsuan Yang^.
              (^ equal advising)<br>
              <i>Computer Vision and Pattern Recognition Conference, 2024.</i> <br>
              [<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_DrivingGaussian_Composite_Gaussian_Splatting_for_Surrounding_Dynamic_Autonomous_Driving_Scenes_CVPR_2024_paper.html">PDF</a>][<a href="https://pkuvdig.github.io/DrivingGaussian/">Website</a>][<a href="https://pkuvdig.github.io/DrivingGaussian/">Code</a>]
            </p>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="3d-generation selected all">
          <div class="flex-item flex-item-stretch flex-column">
            <video width="240" height="175" src="img/gala3d.mp4" title="generated 3D loading.." playsinline="" autoplay="" loop="" preload="" muted=""></video>
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting</b><br>
              <b>Xiaoyu Zhou</b>, Xingjian Ran, Yajiao Xiong, Jinlin He, Zhiwei Lin, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang.<br>
              <i>International Conference on Machine Learning (ICML), 2024.</i> <br>
              [<a href="https://arxiv.org/abs/2402.07207">PDF</a>][<a href="https://gala3d.github.io/">Website</a>][<a href="https://github.com/VDIGPKU/GALA3D">Code</a>]
            </p>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="3d-reconstruction selected all">
          <div class="flex-item flex-item-stretch flex-column">
            <img width="240" height="145" src="img/hqgs.png" title="method preview"><br>
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>HQGS: High-Quality Novel View Synthesis with Gaussian Splatting in Degraded Scenes</b><br>
              Xin Lin*, Shi Luo*, Xiaojun Shan, <b>Xiaoyu Zhou</b>, Chao Ren, Lu Qi, Ming-Hsuan Yang, Nuno Vasconcelos. 
              (* equal contribution) <br>
              <i>International Conference on Learning Representations (ICLR), 2025.</i> <br>
              [<a href="https://openreview.net/forum?id=25Zlvl7JxW&">PDF</a>][<a href="https://github.com/linxin0/HQGS">Code</a>]
            </p>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="3d-understanding selected all">
          <div class="flex-item flex-item-stretch flex-column">
            <img width="240" height="145" src="img/roburcdet.png" title="method preview"><br>
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>RobuRCDet: Enhancing Robustness of Radar-Camera Fusion in Bird's Eye View for 3D Object Detection</b><br>
              Jingtong Yue, Zhiwei Lin, Xin Lin, Xiaoyu Zhou, Xiangtai Li, Lu Qi, Yongtao Wang, Ming-Hsuan Yang.
              (* equal contribution)<br>
              <i>International Conference on Learning Representations (ICLR), 2025.</i> <br>
              [<a href="https://arxiv.org/pdf/2502.13071">PDF</a>][<a href="https://github.com/Jingtong0527/RobuRCDet">Code</a>]
            </p>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="3d-understanding selected all">
          <div class="flex-item flex-item-stretch flex-column">
            <video width="240" height="155" src="img/autoocc.mp4" title="auto-annotation results loading.." playsinline="" autoplay="" loop="" preload="" muted=""></video><br>
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>AutoOcc: Automatic Open-Ended Semantic Occupancy Annotation via Vision-Language Guided Gaussian Splatting</b><br>
              <b>Xiaoyu Zhou</b>, Jingqi Wang, Yongtao Wang, Yufei Wei, Nan Dong, Ming-Hsuan Yang. <br>
              <i>International Conference on Computer Vision (ICCV), 2025.</i> <br>
              [<a href="https://arxiv.org/pdf/2502.04981">PDF</a>]
            </p>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="all">
          <div class="flex-item flex-item-stretch flex-column">
            <img width="240" height="145" src="img/avoiddf.png" title="method preview"><br>
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>AVoiD-DF: Audio-Visual Joint Learning for Detecting Deepfake</b><br>
              Wenyuan Yang, <b>Xiaoyu Zhou</b>, Zhikai Chen, Bofei Guo, Zhongjie Ba, Zhihua Xia, Xiaochun Cao, Kui Ren.
              <br>
              <i>IEEE Transactions on Information Forensics and Security, 2023.</i> <br>
              [<a href="https://ieeexplore.ieee.org/abstract/document/10081373">PDF</a>]
            </p>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="all">
          <div class="flex-item flex-item-stretch flex-column">
            <img width="240" height="145" src="img/mavtfg.png" title="method preview"><br>
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>MAVT-FG: Multimodal Audio-Visual Transformer for Weakly-supervised Fine-Grained Recognition</b><br>
              <b>Xiaoyu Zhou</b>b>, Xiaotong Song, Hao Wu, Jingran Zhang, Xing Xu.<br>
              <i>ACM International Conference on Multimedia, 2023.</i> <br>
              [<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548383">PDF</a>]
            </p>
          </div>
        </div>

        <div class="flex-row publication-item" data-categories="3d-reconstruction selected all">
          <div class="flex-item flex-item-stretch flex-column">
            <img width="240" height="125" src="img/dg++.png" alt="method preview">
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>DrivingGaussian++: Towards Realistic Reconstruction and Editable Simulation for Surrounding Dynamic Driving Scenes</b><br>
              Yajiao* Xiong, <b>Xiaoyu Zhou*</b>, Yongtao Wan, Deqing Sun, Ming-Hsuan Yang.
              (* equal contribution) <br>
              <i>ArXiv, 2025.</i> <br>
              [<a href="https://arxiv.org/abs/2508.20965">PDF</a>][<a href="https://xiong-creator.github.io/DrivingGaussian_plus.github.io/">Website</a>]
            </p>
          </div>
        </div>

        
        <!--End Publications-->
        <!-------------------------------------------------------------------------------------------->
        <!--Experience-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Experience</h2>
            <hr>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-item-stretch flex-column">
            <img width="130" height="130" src="./img/pku.png">
            <!-- <img class="image max-width-400" src="img/dummay-img.png"> -->
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>VDIG Lab, Peking University</b><br>
              PhD Student<br>
              Sep. 2023 - Now<br>
              Work with <a href="https://scholar.google.com/citations?user=Zna90HQAAAAJ&hl=zh-CN">Yongtao Wang</a>, <a href="https://scholar.google.com/citations?user=t4rgICIAAAAJ&hl=zh-CN">Deqing Sun</a>, <a href="https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=zh-CN">Ming-Hsuan Yang</a><br>
            </p>
          </div>
        </div>
        <!--End Experience-->
        <!-------------------------------------------------------------------------------------------->
        <!--Talks&Presentations-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Honors & Awards</h2>
            <hr>
            <ul>
              <li>
                [05/2025] Academic Innovation Award @ Peking University
              </li>
              <li>
                [12/2024] Wangxuan Institute of Computer Technology Scholarship
                @ Peking University
              </li>
              <li>
                [09/2024] Peking University Presidential Scholarship (top honor for PhD students) 
                @ Peking University
              </li>
              <li>
                [04/2024] FunTech Science & Innovation Fund (1 out of 20 nationwide)
                @ Nationwide
              </li>
              <li>
                [12/2023] SenseTime Scholarship (1 out of 30 AI researchers nationwide)
                @ Nationwide
              </li>
              <li>
                [10/2023] National Scholarship, First Prize
                @ Nationwide
              </li>
              <li>
                [08/2023] Internet Innovation and Technology Competition, Gold Medal 
                @ Nationwide
              </li>
              <li>
                [06/2023] International Mathematical Contest in Modeling, Finalist 
                @ Worldwide
              </li>
              <li>
                [04/2023] National Information Security Competition, Second Prize
                @ Nationwide
              </li>
              <li>
                [03/2023] National Computer Design Competition, Second Prize
                @ Nationwide
              </li>
              <li>
                [01/2023] International Innovation Competition, Bronze Medal 
                @ Nationwide
              </li>
            </ul>
          </div>
        </div>
        <!--End Talks&Presentations-->
        <!-------------------------------------------------------------------------------------------->
        <!--Teaching Assistant-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Teaching Assistant</h2>
            <hr>
            <ul>
              <li>
                [Spring 2023/2024] Scientific Research Method
              </li>
            </ul>
          </div>
        </div>
        <!--End Talks&Presentations-->
        <!-------------------------------------------------------------------------------------------->
        <!--Projects-->
        <!-- <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Projects</h2>
            <hr>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-item-stretch flex-column">
            <iframe width="240" height="135" src="https://www.youtube.com/embed/UXPBjkAp3-M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>3D Scene Semantic Modeling</b><br>
            </p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-item-stretch flex-column">
            <img width="240" height="135" src="img/flow-disp.jpg">
          </div>
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">
              <b>Deep Scene Flow Estimation with Iterative Soft-argmin and Edge-aware Regression</b><br>
              Proposed an edge-aware policy to improve the over-smoothing problem and utilized contrastive loss to learn a more
              discriminative descriptor.<br>
              Proposed an iterative soft argmin to cope with the multi-modal distributions of cost volume.<br>
            </p>
          </div>
        </div> -->
        <!--End Projects-->
        <div class="flex-row">
          <div class="flex-item flex-column">
          </div>
          <div class="flex-item flex-column">
          </div>
        </div>
      </div>
    </div>
  </div>
</body>

</html>

